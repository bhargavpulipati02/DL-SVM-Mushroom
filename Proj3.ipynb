{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pathlib\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Dataset path\n",
        "data_dir = pathlib.Path('/content/drive/MyDrive/Mushrooms')\n",
        "class_names = sorted([item.name for item in data_dir.iterdir() if item.is_dir()])\n",
        "class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
        "\n",
        "# Check and load valid images\n",
        "def is_valid_image(filepath):\n",
        "    try:\n",
        "        img = tf.io.read_file(filepath)\n",
        "        tf.image.decode_jpeg(img)\n",
        "        return True\n",
        "    except tf.errors.InvalidArgumentError:\n",
        "        return False\n",
        "\n",
        "valid_images, valid_labels = [], []\n",
        "for cls in class_names:\n",
        "    for path in (data_dir / cls).glob(\"*.jpg\"):\n",
        "        if is_valid_image(str(path)):\n",
        "            valid_images.append(str(path))\n",
        "            valid_labels.append(class_to_idx[cls])\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((valid_images, valid_labels))\n",
        "dataset = dataset.shuffle(len(valid_images), seed=123)\n",
        "train_size = int(0.8 * len(valid_images))\n",
        "train_ds = dataset.take(train_size)\n",
        "val_ds = dataset.skip(train_size)\n",
        "\n",
        "def preprocess(path, label):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img, label\n",
        "\n",
        "train_ds = train_ds.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# ===  Data Augmentation Layer  ===\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomRotation(0.01),\n",
        "    tf.keras.layers.RandomZoom(0.01),\n",
        "])\n",
        "\n",
        "# Step 1: Build + Train CNN with softmax using Functional API\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "inputs = layers.Input(shape=(224, 224, 3))\n",
        "x = data_augmentation(inputs)  # tiny augmentation applied only here\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "outputs = layers.Dense(len(class_names), activation='softmax')(x)\n",
        "\n",
        "full_model = models.Model(inputs, outputs)\n",
        "\n",
        "full_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "full_model.fit(train_ds, epochs=30, validation_data=val_ds)\n",
        "\n",
        "# Step 2: Create feature extractor (cut off softmax)\n",
        "feature_extractor = tf.keras.Model(\n",
        "    inputs=full_model.input,\n",
        "    outputs=full_model.layers[-2].output  # second-to-last layer (Dense(128))\n",
        ")\n",
        "\n",
        "# Step 3: Extract features\n",
        "def extract_features(dataset, extractor):\n",
        "    features, labels = [], []\n",
        "    for imgs, lbls in dataset:\n",
        "        feats = extractor.predict(imgs, verbose=0)\n",
        "        features.append(feats)\n",
        "        labels.append(lbls.numpy())\n",
        "    return np.vstack(features), np.concatenate(labels)\n",
        "\n",
        "train_features, train_labels = extract_features(train_ds, feature_extractor)\n",
        "val_features, val_labels = extract_features(val_ds, feature_extractor)\n",
        "\n",
        "# Step 4: Train SVM on extracted features\n",
        "svm_clf = SVC(kernel='linear')\n",
        "svm_clf.fit(train_features, train_labels)\n",
        "\n",
        "# Step 5: Evaluate SVM\n",
        "val_preds = svm_clf.predict(val_features)\n",
        "accuracy = accuracy_score(val_labels, val_preds)\n",
        "print(f\"SVM classifier accuracy on validation set: {accuracy * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT_wgrGi7HGT",
        "outputId": "c895144d-d16c-4d91-b4c4-21c201b99834"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2335 - loss: 2.0864 - val_accuracy: 0.3252 - val_loss: 1.8098\n",
            "Epoch 2/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.3613 - loss: 1.7722 - val_accuracy: 0.4209 - val_loss: 1.6607\n",
            "Epoch 3/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.4386 - loss: 1.6061 - val_accuracy: 0.5093 - val_loss: 1.4396\n",
            "Epoch 4/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.4862 - loss: 1.4954 - val_accuracy: 0.5130 - val_loss: 1.3785\n",
            "Epoch 5/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.5400 - loss: 1.3576 - val_accuracy: 0.5397 - val_loss: 1.2805\n",
            "Epoch 6/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.5520 - loss: 1.3261 - val_accuracy: 0.5820 - val_loss: 1.2440\n",
            "Epoch 7/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.6182 - loss: 1.1449 - val_accuracy: 0.6578 - val_loss: 1.0253\n",
            "Epoch 8/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.6393 - loss: 1.0880 - val_accuracy: 0.6563 - val_loss: 1.0103\n",
            "Epoch 9/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.6675 - loss: 1.0273 - val_accuracy: 0.7327 - val_loss: 0.8798\n",
            "Epoch 10/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.7067 - loss: 0.9105 - val_accuracy: 0.6949 - val_loss: 0.8794\n",
            "Epoch 11/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.7302 - loss: 0.8478 - val_accuracy: 0.7157 - val_loss: 0.7929\n",
            "Epoch 12/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.7635 - loss: 0.7663 - val_accuracy: 0.8352 - val_loss: 0.5740\n",
            "Epoch 13/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.8073 - loss: 0.6675 - val_accuracy: 0.7862 - val_loss: 0.6189\n",
            "Epoch 14/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.8151 - loss: 0.6347 - val_accuracy: 0.8731 - val_loss: 0.4652\n",
            "Epoch 15/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.8412 - loss: 0.5633 - val_accuracy: 0.8849 - val_loss: 0.3975\n",
            "Epoch 16/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.8675 - loss: 0.4743 - val_accuracy: 0.8976 - val_loss: 0.3611\n",
            "Epoch 17/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.8757 - loss: 0.4465 - val_accuracy: 0.8575 - val_loss: 0.4049\n",
            "Epoch 18/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.8827 - loss: 0.4064 - val_accuracy: 0.9146 - val_loss: 0.2852\n",
            "Epoch 19/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9104 - loss: 0.3408 - val_accuracy: 0.9480 - val_loss: 0.2139\n",
            "Epoch 20/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9137 - loss: 0.3275 - val_accuracy: 0.9740 - val_loss: 0.1728\n",
            "Epoch 21/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9270 - loss: 0.2846 - val_accuracy: 0.9384 - val_loss: 0.2229\n",
            "Epoch 22/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9367 - loss: 0.2629 - val_accuracy: 0.9651 - val_loss: 0.1531\n",
            "Epoch 23/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9506 - loss: 0.2140 - val_accuracy: 0.9547 - val_loss: 0.1769\n",
            "Epoch 24/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9552 - loss: 0.1974 - val_accuracy: 0.9740 - val_loss: 0.1243\n",
            "Epoch 25/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9592 - loss: 0.1700 - val_accuracy: 0.9451 - val_loss: 0.1811\n",
            "Epoch 26/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9612 - loss: 0.1680 - val_accuracy: 0.9762 - val_loss: 0.1078\n",
            "Epoch 27/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9726 - loss: 0.1366 - val_accuracy: 0.9889 - val_loss: 0.0725\n",
            "Epoch 28/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9760 - loss: 0.1243 - val_accuracy: 0.9681 - val_loss: 0.1110\n",
            "Epoch 29/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9797 - loss: 0.1147 - val_accuracy: 0.9844 - val_loss: 0.0878\n",
            "Epoch 30/30\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9782 - loss: 0.1030 - val_accuracy: 0.9918 - val_loss: 0.0575\n",
            "SVM classifier accuracy on validation set: 99.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate CNN directly on validation set\n",
        "cnn_eval = full_model.evaluate(val_ds)\n",
        "print(f\"CNN softmax accuracy on validation set: {cnn_eval[1] * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_4Zt5oW1asx",
        "outputId": "b4167828-56de-4ebc-c35b-6e94d4d347d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9813 - loss: 0.0732\n",
            "CNN softmax accuracy on validation set: 98.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Save models\n",
        "full_model.save('trained_cnn_model.keras')\n",
        "joblib.dump(svm_clf, 'trained_svm_classifier.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNiWV4oPzCgG",
        "outputId": "2c9da517-37a2-4984-b32d-628b590cc2e1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trained_svm_classifier.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}